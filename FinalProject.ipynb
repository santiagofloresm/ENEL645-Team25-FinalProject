{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "colab": {
      "name": "FinalProject.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y009cMb97AqX"
      },
      "source": [
        "# Final Project\r\n",
        "## Team 25\r\n",
        "Santiago Flores - 30119885\r\n",
        "\r\n",
        "Davis Allan - 10016543\r\n",
        "\r\n",
        "Jordan Joorisity - 30117950\r\n",
        "\r\n",
        "Patrick Pickard - 30116807\r\n",
        "\r\n",
        "Joshua Posyluzny - 30118206"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tddy3W1mPu1"
      },
      "source": [
        "# 1. Loading and pre-processing the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbIf6oK7Ewow"
      },
      "source": [
        "### 1.1 Mount your Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0be_4nRmTgx"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJkGof40E1eH"
      },
      "source": [
        "### 1.2 Load you Kaggle API token\r\n",
        "In order to use the Kaggle’s public API, you must first authenticate using an API token. From the site header, click on your user profile picture, then on “My Account” from the dropdown menu. This will take you to your account settings at https://www.kaggle.com/account. Scroll down to the section of the page labelled API:\r\n",
        "\r\n",
        "To create a new token, click on the “Create New API Token” button. This will download a fresh authentication token onto your machine. Reference: (https://www.kaggle.com/docs/api)\r\n",
        "\r\n",
        "With the json token downloaded run the cell below and upload the file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrfXamW4m4Uz"
      },
      "source": [
        "from google.colab import files\r\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dy4ga0S6GXLR"
      },
      "source": [
        "# Moves your API token key \r\n",
        "!mkdir -p ~/.kaggle\r\n",
        "!cp kaggle.json ~/.kaggle/\r\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Us1yFM9MFk0O"
      },
      "source": [
        "### 1.3 Download and unzip the datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wETheo64n0nq"
      },
      "source": [
        "!kaggle datasets download -d grassknoted/asl-alphabet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8UJSpovoSna"
      },
      "source": [
        "import zipfile\r\n",
        "zip_ref = zipfile.ZipFile('asl-alphabet.zip', 'r')\r\n",
        "zip_ref.extractall('files')\r\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8TSXTtCtetO"
      },
      "source": [
        "!kaggle datasets download -d danrasband/asl-alphabet-test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VILwb7rvuGXo"
      },
      "source": [
        "zip_ref = zipfile.ZipFile('asl-alphabet-test.zip', 'r')\r\n",
        "zip_ref.extractall('files')\r\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtM5vruqQJDJ"
      },
      "source": [
        "### 1.4 Data display"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDPUZkTqfp1J"
      },
      "source": [
        "There are 29 classes in the dataset, one for each letter in the English alphabet, one for space, one for delete and a blank one. Below is an exmaple of each one"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TqIFGd_Ee6B"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "train_folder = 'files/asl_alphabet_train/asl_alphabet_train/'\r\n",
        "validation_folder = 'files/asl-alphabet-test/'\r\n",
        "classes = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', \r\n",
        "           'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', \r\n",
        "           'W', 'X', 'Y', 'Z', 'nothing', 'space', 'del']\r\n",
        "\r\n",
        "plt.figure(figsize=(11,11))\r\n",
        "for i in range (0,29):\r\n",
        "  plt.subplot(7,7, i+1)\r\n",
        "  plt.xticks([])\r\n",
        "  plt.yticks([])\r\n",
        "  path = train_folder + classes[i] + \"/\" + classes[i] + \"1.jpg\"\r\n",
        "  img = plt.imread(path)\r\n",
        "  plt.imshow(img)\r\n",
        "  plt.xlabel(classes[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZBuXYcdg6_I"
      },
      "source": [
        "### 1.5 Saving the datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHNMAdyROz0w"
      },
      "source": [
        "import os\r\n",
        "import cv2\r\n",
        "\r\n",
        "def load_images(image_folder, images, labels):\r\n",
        "  num = -1\r\n",
        "  for folder in os.listdir(image_folder):\r\n",
        "    num += 1\r\n",
        "    for image in os.listdir(image_folder + \"/\" + folder):\r\n",
        "      temp_img = cv2.imread(image_folder + \"/\" + folder + \"/\" + image)\r\n",
        "      images.append(temp_img)\r\n",
        "      labels.append(folder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHC2oMGErNOU"
      },
      "source": [
        "1.5.1 Training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "os3lkPcbr7mE"
      },
      "source": [
        "train_images = []\r\n",
        "train_labels = []\r\n",
        "\r\n",
        "load_images(train_folder, train_images, train_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1o8FVWarSKQ"
      },
      "source": [
        "1.5.2 Test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zjxrtthspux_"
      },
      "source": [
        "validation_images = []\r\n",
        "validation_labels = []\r\n",
        "\r\n",
        "load_images(validation_folder, validation_images, validation_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grxlYNs4G-3R"
      },
      "source": [
        "  h, w, r = train_images[0].shape\r\n",
        "  print('There are', len(train_images), 'images for training the model')\r\n",
        "  print(len(train_labels)//len(set(train_labels)), 'images per category')\r\n",
        "  print('The shape of each image is', train_images[0].shape)\r\n",
        "  print('From which:')\r\n",
        "  print('The width is', w)\r\n",
        "  print('The height is', h)\r\n",
        "  print('And each pixel has a value for each component of RGB for a total of', r)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqkcQEc5tcED"
      },
      "source": [
        "### 1.6 One Hot Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luUZ5Q-PqhnM"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "from sklearn.preprocessing import OneHotEncoder\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "train_labels_df = pd.DataFrame(train_labels, columns=['Character'])\r\n",
        "labelencoder = LabelEncoder()\r\n",
        "onehotencoder = OneHotEncoder()\r\n",
        "\r\n",
        "train_labels_df['label'] = labelencoder.fit_transform(train_labels_df['Character'])\r\n",
        "train_labels_onehot = pd.DataFrame(onehotencoder.fit_transform(train_labels_df[['label']]).toarray())\r\n",
        "\r\n",
        "# train_labels_df.drop_duplicates()\r\n",
        "train_labels_onehot[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_rW_WAYV5i4"
      },
      "source": [
        "validation_labels_df = pd.DataFrame(validation_labels, columns=['Character'])\r\n",
        "\r\n",
        "validation_labels_df['label'] = labelencoder.fit_transform(labels_df['Character'])\r\n",
        "validation_labels_onehot = pd.DataFrame(onehotencoder.fit_transform(labels_df[['label']]).toarray())\r\n",
        "\r\n",
        "validation_labels_df.drop_duplicates()\r\n",
        "# validation_labels_onehot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnPQMr48tm-p"
      },
      "source": [
        "### 1.7 Train test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9N-4mj1lL4x"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(train_images, train_labels_onehot, \r\n",
        "                                                    test_size=0.2, \r\n",
        "                                                    stratify=train_labels,\r\n",
        "                                                    random_state=21)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcG2ZZ-um4Ef"
      },
      "source": [
        "print('After the split there are:')\r\n",
        "print(len(X_train), 'images on the train split')\r\n",
        "print(len(X_test), 'images on the test split')\r\n",
        "print('For each category 80% of the images are in the train split and 20% in the test split')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}